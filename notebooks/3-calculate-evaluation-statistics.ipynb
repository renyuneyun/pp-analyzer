{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import src.annotation_utils as a_utils\n",
    "import src.llm_utils as llm_utils\n",
    "import src.stats_utils as s_utils\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BRAT_DATA_PATH = os.environ['BRAT_DATA_PATH']\n",
    "DATA_DEF_FILE = os.environ['DATA_CATEGORY_DEFINITION']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved queries (for model evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model': 'gpt-4o-2024-08-06', 'description': 'data_span-sent_entity'},\n",
       " 1067,\n",
       " {'input': [{'role': 'system',\n",
       "    'content': 'You are an annotation expert. You will be given a segment of a privacy policy of a web or mobile application, and will be asked to annotate entities in it.\\nPlease annotate the given sentence of privacy policy for data entities, and adhere to the following guidelines:\\n\\nIMPORTANT: Filtering Out General Phrases\\nBefore annotating, carefully check each potential data entity. DO NOT annotate general phrases that do not provide specific data types.\\nExamples of general phrases to omit include, but are not limited to:\\n\\n\"the information we collect about you\"\\n\"other data\"\\n\"any information\"\\n\\nIf a phrase does not clearly indicate a specific type of personal data, DO NOT include it in your annotations.\\n\\nData entities are refers to the phrases that mention PERSONAL DATA OF THE USER which is being mentioned in one of the following context types:\\n1. first-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by the first party (the application).\\n2. third-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by a third party.\\n3. third-party-sharing-disclosure - the policy segment mentions sharing, or disclosure of this datum to a third party.\\n4. data-storage-retention-deletion - the policy segment mentions storage, retention, or deletion of this datum.\\n5. data-security-protection - the policy segment mentions how this datum is being protected.\\n\\nNote the following!\\n1. Personal user data that is mentioned outside of one of these contexts does not classify as data entity and should NOT be annotated.\\n2. Multiple contexts may apply to the same data entity.\\n3. Tracking technologies such as cookies, web beacons, etc. are technologies, hence does not classify as data entity and should NOT be annotated.\\n4. The data segment that you receive might be empty or not contain any information on usage of concrete personal user data - that\\'s normal, and you should just return an empty list.\\n\\nIn the following prompt, you will receive a sentence, and your task is to find the data entities in the sentence.\\nProvide the output as a list of data entities. Output only the exact text of the data entity as it appears in the text segment.\\nDo not include any additional information or context in your annotations.\\nRepresent the data entities as a JSON array of entries, following the order of their appearance in the segment.\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Please annotate the following sentence:\\n\\nd. We may share your information publicly and with our partners such as third-party content providers, advertisers or connected sites, but in a manner which does not reveal your personally-identifiable information and which is aggregated with other user information to show usage of EMI and third-party products and services offered on our Service and trends based on such categories as age, gender, geographical origination and other demographic characteristics.\\n'}],\n",
       "  'output': '[]',\n",
       "  'correct_output': '[]'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dir = 'eval-2024-09-14-15-17-57-gpt-4o-mini-2024-07-18'\n",
    "eval_dir = None\n",
    "eval_dir = '/home/ryey/workspaces/oxford/PP-DToU/fine-tune/out/exp/eval-2024-09-17-22-35-35-gpt-4o-2024-08-06'\n",
    "\n",
    "desc, saved_queries = list(llm_utils.load_saved_llm_queries(eval_dir))\n",
    "desc, len(saved_queries), saved_queries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate statistics for model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat for eval with desc: {'model': 'gpt-4o-2024-08-06', 'description': 'data_span-sent_entity'}\n",
      "  1066 valid datapoints, avg. precission, recall, f1: [0.91178744 0.93791441 0.91785393]\n",
      "  93 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.24693991 0.54641678 0.31647621]\n",
      "  973 (ought to be) empty datapoints, avg. precission, recall, f1: [0.97533402 0.97533402 0.97533402]\n",
      "  1 datapoints are not valid (e.g. not JSON; malformed model output)\n",
      "  {462: ('```json\\n'\n",
      "       '[\\n'\n",
      "       '    \"unique identification numbers associated with your device '\n",
      "       '(\\\\\"Device ID\\\\\")\",\\n'\n",
      "       '    \"mobile carrier\",\\n'\n",
      "       '    \"device type\",\\n'\n",
      "       '    \"manufacturer\",\\n'\n",
      "       '    \"phone number\",\\n'\n",
      "       '    \"geographical location data\",\\n'\n",
      "       '    \"GPS coordinates (e.g. latitude and/or longitude)\"\\n'\n",
      "       ']\\n'\n",
      "       '```',\n",
      "       '[\"geographical location data\", \"similar information regarding the '\n",
      "       'location of your mobile device\"]')}\n"
     ]
    }
   ],
   "source": [
    "s_utils.calc_and_print_statistics(desc, saved_queries, try_heuristic_parse=True, lcs_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 valid datapoints, avg. precission, recall, f1: [0.02842466 0.02796804 0.02663079]\n",
      "10 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.415      0.40833333 0.38880952]\n",
      "136 (ought to be) empty datapoints, avg. precission, recall, f1: [0. 0. 0.]\n",
      "0 datapoints are not valid JSON\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For query '2024-09-13-00-44-00-6cbf289f-798c-46ff-8d72-221b0da1099e'\n",
    "# For model 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-content-only-from-api:A6cig7w6'\n",
    "# print(np.mean(result_score_list, axis=0))\n",
    "print(f\"{len(result_score_list)} valid datapoints, avg. precission, recall, f1:\", np.mean(result_score_list, axis=0))\n",
    "print(f\"{len(non_empty_result_score_list)} (ought to be) non-empty datapoints, avg. precission, recall, f1:\", np.mean(non_empty_result_score_list, axis=0))\n",
    "print(f\"{len(empty_result_score_list)} (ought to be) empty datapoints, avg. precission, recall, f1:\", np.mean(empty_result_score_list, axis=0))\n",
    "print(f\"{len(failed)} datapoints are not valid JSON\")\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 valid datapoints, avg. precission, recall, f1: [0.78908855 0.80578704 0.78842856]\n",
      "21 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.2680358  0.38253968 0.26351015]\n",
      "123 (ought to be) empty datapoints, avg. precission, recall, f1: [0.87804878 0.87804878 0.87804878]\n",
      "2 datapoints are not valid JSON\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{54: ('[] reflections of persona data entities []', '[]'),\n",
       " 67: ('[\"name\": \"Device ID\", \"type\": \"identification numbers associated with your device\", \"type\": \"personal information\"]',\n",
       "  '[\"geographical location data\", \"similar information regarding the location of your mobile device\", \"location data\", \"web request\", \"browser type\", \"referring / exit pages and URLs\", \"domain names\", \"landing pages\"]')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For query '2024-09-13-11-25-49-a393b3ea-6ae0-4433-8e92-610bd63e1305'\n",
    "# For model 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-with-empty-from-api:A6o1jAxy'\n",
    "\n",
    "print(f\"{len(result_score_list)} valid datapoints, avg. precission, recall, f1:\", np.mean(result_score_list, axis=0))\n",
    "print(f\"{len(non_empty_result_score_list)} (ought to be) non-empty datapoints, avg. precission, recall, f1:\", np.mean(non_empty_result_score_list, axis=0))\n",
    "print(f\"{len(empty_result_score_list)} (ought to be) empty datapoints, avg. precission, recall, f1:\", np.mean(empty_result_score_list, axis=0))\n",
    "print(f\"{len(failed)} datapoints are not valid JSON\")\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 12 12\n",
      "Stat for eval with desc: {'model': 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-with-empty-from-api:A6o1jAxy'}\n",
      "  133 valid datapoints, avg. precission, recall, f1: [0.81938179 0.8245614  0.82119585]\n",
      "  10 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.09777778 0.16666667 0.12190476]\n",
      "  123 (ought to be) empty datapoints, avg. precission, recall, f1: [0.87804878 0.87804878 0.87804878]\n",
      "  1 datapoints are not valid JSON\n",
      "  {53: ('[] reflections of persona data entities []', '[]')}\n",
      "Stat for eval with desc: {'model': 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-no-empty-from-api:A70TvfoL'}\n",
      "  134 valid datapoints, avg. precission, recall, f1: [0.02860697 0.03358209 0.03059701]\n",
      "  10 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.38333333 0.45       0.41      ]\n",
      "  124 (ought to be) empty datapoints, avg. precission, recall, f1: [0. 0. 0.]\n",
      "  0 datapoints are not valid JSON\n",
      "  {}\n",
      "Stat for eval with desc: {'model': 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-with-empty-from-api:A6o1jAxy'}\n",
      "  11 valid datapoints, avg. precission, recall, f1: [0.42281582 0.57878788 0.39224232]\n",
      "  11 (ought to be) non-empty datapoints, avg. precission, recall, f1: [0.42281582 0.57878788 0.39224232]\n",
      "  0 (ought to be) empty datapoints, avg. precission, recall, f1: nan\n",
      "  1 datapoints are not valid JSON\n",
      "  {11: ('[\"name\": \"Device ID\", \"type\": \"identification numbers associated with '\n",
      "      'your device\", \"type\": \"personal information\"]',\n",
      "      '[\"geographical location data\", \"similar information regarding the '\n",
      "      'location of your mobile device\", \"location data\", \"web request\", '\n",
      "      '\"browser type\", \"referring / exit pages and URLs\", \"domain names\", '\n",
      "      '\"landing pages\"]')}\n",
      "Stat for eval with desc: {'model': 'ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-no-empty-from-api:A70TvfoL'}\n",
      "  12 valid datapoints, avg. precission, recall, f1: [0. 0. 0.]\n",
      "  0 (ought to be) non-empty datapoints, avg. precission, recall, f1: nan\n",
      "  12 (ought to be) empty datapoints, avg. precission, recall, f1: [0. 0. 0.]\n",
      "  0 datapoints are not valid JSON\n",
      "  {}\n"
     ]
    }
   ],
   "source": [
    "def compare_two_evaluations(eval1, eval2):\n",
    "    desc1, saved_queries1 = eval1\n",
    "    desc2, saved_queries2 = eval2\n",
    "\n",
    "    def to_reserve_map(saved_queries):\n",
    "        reverse_map = {}\n",
    "        for query in saved_queries:\n",
    "            key = (str(query['input'][1]), str(query['correct_output']))\n",
    "            reverse_map[key] = query\n",
    "        return reverse_map\n",
    "\n",
    "    reverse_map1 = to_reserve_map(saved_queries1)\n",
    "    reverse_map2 = to_reserve_map(saved_queries2)\n",
    "\n",
    "    ## Calculate what keys are common, and what keys are unique to each\n",
    "    common_keys = set(reverse_map1.keys()) & set(reverse_map2.keys())\n",
    "    unique_keys1 = set(reverse_map1.keys()) - set(reverse_map2.keys())\n",
    "    unique_keys2 = set(reverse_map2.keys()) - set(reverse_map1.keys())\n",
    "\n",
    "    print(len(common_keys), len(unique_keys1), len(unique_keys2))\n",
    "\n",
    "    # Return the common and unique queries\n",
    "    common_queries1 = []\n",
    "    common_queries2 = []\n",
    "    unique_queries1 = []\n",
    "    unique_queries2 = []\n",
    "    for key in common_keys:\n",
    "        common_queries1.append(reverse_map1[key])\n",
    "        common_queries2.append(reverse_map2[key])\n",
    "    for key in unique_keys1:\n",
    "        unique_queries1.append(reverse_map1[key])\n",
    "    for key in unique_keys2:\n",
    "        unique_queries2.append(reverse_map2[key])\n",
    "\n",
    "    return common_queries1, common_queries2, unique_queries1, unique_queries2\n",
    "\n",
    "\n",
    "queries_to_load = [\n",
    "    # '2024-09-13-00-44-00-6cbf289f-798c-46ff-8d72-221b0da1099e',\n",
    "    '2024-09-13-11-25-49-a393b3ea-6ae0-4433-8e92-610bd63e1305',\n",
    "    '2024-09-13-14-48-28-ft:gpt-4o-mini-2024-07-18:rui:30-train-5-val-no-empty-from-api:A70TvfoL',\n",
    "]\n",
    "eval1, eval2 = [llm_utils.load_saved_llm_queries(query) for query in queries_to_load[:2]]\n",
    "common_queries1, common_queries2, unique_queries1, unique_queries2 = compare_two_evaluations(eval1, eval2)\n",
    "\n",
    "\n",
    "calc_and_print_statistics(eval1[0], common_queries1)\n",
    "calc_and_print_statistics(eval2[0], common_queries2)\n",
    "calc_and_print_statistics(eval1[0], unique_queries1)\n",
    "calc_and_print_statistics(eval2[0], unique_queries2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m(340)\u001b[0;36mdecode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    338 \u001b[0;31m        \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    339 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 340 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    341 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    342 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "'[] reflections of persona data entities []'\n",
      "'[] reflections of persona data entities []'\n",
      "'[] reflections of persona data entities []'\n",
      "'[] reflections of persona data entities []'\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
