{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import src.annotation_utils as a_utils\n",
    "import src.llm_utils as llm_utils\n",
    "import src.message_utils as m_utils\n",
    "from src.env import (\n",
    "    BRAT_DATA_PATH,\n",
    ")\n",
    "import os\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from a previous fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc_dir = None\n",
    "\n",
    "training_set, validation_set, test_set, fine_tuned_model_id = llm_utils.load_eval_info(job_desc_dir)\n",
    "\n",
    "len(training_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or, Load a fresh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are an annotation expert. You will be given a segment of a privacy policy of a web or mobile application, and will be asked to annotate purpose entities in it.\\n\\nIMPORTANT: Filtering Out General Phrase\\nBefore annotating, carefully check each potential purpose entity. DO NOT annotate general phrases that do not provide specific purpose types.\\nExamples of general phrases to omit include, but are not limited to:\\n\\n\"other purposes\"\\n\"purposes described in our policy\"\\n\\nPurpose entities are phrases in segment text that refer to the purposes for which USER\\'S PERSONAL DATA will be used, collected, processed, protected, shared with the third parties, etc. The purpose entity must be mentioned in one of the following context types:\\n1. first-party-collection-use - the policy segment mentions collection, usage, processing, storage, retention, deletion, or protection of personal user datum or data by the first party (the application).\\n2. third-party-collection-use - the policy segment mentions collection, usage, or processing of a personal user datum or data by a third party.\\n3. third-party-sharing-disclosure - the policy segment mentions sharing, or disclosure of a personal user datum or data to a third party.\\n\\nNote the following!\\n1. Purpose that is mentioned outside of one of these contexts does not classify as purpose entity and should NOT be annotated.\\n2. Purpose that does not have a clear and concrete personal user data that it applies to does not classify as purpose entity and should NOT be annotated.\\n3. Multiple contexts may apply to the same purpose entity.\\n\\nProvide the output as a list of purpose entities with the following details for each entity:\\n1. The type of the context in which this purpose is mentioned.\\n2. The exact text of the purpose entity as it appears in the text segment.\\n\\nPlease identify and annotate ALL purpose entities in the following privacy policy segment from user\\'s prompt. Remember to ignore purpose entities that do not constitute a concrete purpose.\\nProvide the output as a list of purposes. Output only the exact text of the purpose as it appears in the text segment.\\nDo not include any additional information or context in your annotations.\\nRepresent the purposes as a JSON array of entries, following the order of their appearance in the segment.\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Please annotate the following sentence:\\n\\n101 Great Goals Privacy Policy\\n'},\n",
       "   {'role': 'assistant', 'content': '[]'}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For (segment, data_span)\n",
    "# data_entities = a_utils.load_data_entities_of_segments()\n",
    "\n",
    "# data_entities = [segment for segment in data_entities if segment['entities']]\n",
    "\n",
    "# For data span\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_segment(data_entities)\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_segment_1_1(data_entities)\n",
    "# For data classification\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment(data_entities)\n",
    "# For data classification (gradual, level 0)\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment_gradual(data_entities)\n",
    "\n",
    "## For (segment, sentence, data_span)\n",
    "# data_entities = a_utils.load_data_entities_of_sentences()\n",
    "# For data span of sentence\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence(data_entities)\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence_1(data_entities)\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence_only(data_entities)\n",
    "\n",
    "\n",
    "## For (sentence, purpose_span)\n",
    "purpose_entities = a_utils.load_purpose_entities_of_sentences()\n",
    "# For purpose span of sentence\n",
    "all_data = m_utils.as_training_data_for_purpose_span_of_sentence_only(purpose_entities)\n",
    "\n",
    "\n",
    "test_set = all_data\n",
    "\n",
    "len(test_set), test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-2024-08-06'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = fine_tuned_model_id if 'fine_tuned_model_id' in locals() else 'gpt-4o-mini-2024-07-18'\n",
    "# model_id = '4.0Ultra'\n",
    "model_id = 'gpt-4o-2024-08-06'\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 867/867 [14:19<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('eval-2024-09-17-22-35-35-gpt-4o-2024-08-06', 867)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_list = [data['messages'][:-1] for data in test_set]\n",
    "correct_outputs = [data['messages'][-1]['content'] for data in test_set]\n",
    "\n",
    "dir_name, obj_model_outputs = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "                                                  batch=False,\n",
    "                                                  desc='data_span-sent_entity')\n",
    "dir_name, len(obj_model_outputs)\n",
    "\n",
    "# Not using batch for some tasks because of rate limit\n",
    "# dir_name, batch_job = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "#                                                   batch=True,\n",
    "#                                                   desc='data_span-seg_entity-ver2')\n",
    "# dir_name, batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_JqFQSt6gdH8BBa7BHgVYpeFH', completion_window='24h', created_at=1726578398, endpoint='/v1/chat/completions', input_file_id='file-bWlE4mEreTE1ns9Va1l1Gr69', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-2024-08-06 in organization org-B2C2pNzAq4paAOvhIYdFJlSv. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1726664798, failed_at=1726578399, finalizing_at=None, in_progress_at=None, metadata={'description': 'data_span-seg_entity-ver2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_utils.wait_for_batch_job_finish(batch_job.id)\n",
    "# llm_utils.retrieve_batch_query_result()\n",
    "# llm_utils.combine_batch_query_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
