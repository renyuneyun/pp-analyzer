{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import src.annotation_utils as a_utils\n",
    "import src.llm_utils as llm_utils\n",
    "import src.message_utils as m_utils\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BRAT_DATA_PATH = os.environ['BRAT_DATA_PATH']\n",
    "DATA_DEF_FILE = os.environ['DATA_DEF_FILE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from a previous fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc_dir = None\n",
    "\n",
    "training_set, validation_set, test_set, fine_tuned_model_id = llm_utils.load_eval_info(job_desc_dir)\n",
    "\n",
    "len(training_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or, Load a fresh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are an annotation expert. You will be given a segment of a privacy policy of a web or mobile application, and will be asked to annotate entities in it.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Please annotate the given segment of privacy policy for data entities, and adhere to the following guidelines:\\n\\nIMPORTANT: Filtering Out General Phrases\\nBefore annotating, carefully check each potential data entity. DO NOT annotate general phrases that do not provide specific data types.\\nExamples of general phrases to omit include, but are not limited to:\\n\\n\"your personal information\"\\n\"the information you share (with us)\"\\n\"the information we collect about you\"\\n\"other data\"\\n\"information about you\"\\n\"personal information\"\\n\"user information\"\\n\"customer data\"\\n\"collected information\"\\n\"any information\"\\n\\nIf a phrase does not clearly indicate a specific type of personal data, DO NOT include it in your annotations.\\n\\nData entities are refers to the phrases that mention PERSONAL DATA OF THE USER which is being mentioned in one of the following context types:\\n1. first-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by the first party (the application).\\n2. third-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by a third party.\\n3. third-party-sharing-disclosure - the policy segment mentions sharing, or disclosure of this datum to a third party.\\n4. data-storage-retention-deletion - the policy segment mentions storage, retention, or deletion of this datum.\\n5. data-security-protection - the policy segment mentions how this datum is being protected.\\n\\nNote the following!\\n1. Personal user data that is mentioned outside of one of these contexts does not classify as data entity and should NOT be annotated.\\n2. Multiple contexts may apply to the same data entity.\\n3. Tracking technologies such as cookies, web beacons, etc. are technologies, hence does not classify as data entity and should NOT be annotated.\\n4. The data segment that you receive might be empty or not contain any information on usage of concrete personal user data - that\\'s normal, and you should just return an empty list.\\n\\nProvide the output as a list of data entities with the following details for each entity:\\n1. The type of the context in which this datum is mentioned.\\n2. The exact text of the data entity as it appears in the text segment.\\n\\nDo not output anything that is not the data entity list, such as explanations or comments.\\n\\nHere is the privacy policy segment to annotate:\\n\\n101 Great Goals Privacy Policy\\nLast revised: May 25, 2018\\n\\n\\n'},\n",
       "   {'role': 'assistant', 'content': '[]'}]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For (segment, data_span)\n",
    "data_entities = a_utils.load_data_entities_of_segments(BRAT_DATA_PATH, DATA_DEF_FILE)\n",
    "\n",
    "# data_entities = [segment for segment in data_entities if segment['entities']]\n",
    "\n",
    "# For data span\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_segment(data_entities)\n",
    "all_data = m_utils.as_training_data_for_data_span_of_segment_1_1(data_entities)\n",
    "# For data classification\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment(data_entities)\n",
    "# For data classification (gradual, level 0)\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment_gradual(data_entities)\n",
    "\n",
    "## For (segment, sentence, data_span)\n",
    "# data_entities = a_utils.load_data_entities_of_sentences(BRAT_DATA_PATH, DATA_DEF_FILE)\n",
    "# For data span of sentence\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence(data_entities)\n",
    "\n",
    "test_set = all_data\n",
    "\n",
    "len(test_set), test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-2024-08-06'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = fine_tuned_model_id if 'fine_tuned_model_id' in locals() else 'gpt-4o-mini-2024-07-18'\n",
    "# model_id = '4.0Ultra'\n",
    "model_id = 'gpt-4o-2024-08-06'\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [03:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('eval-2024-09-17-14-25-30-gpt-4o-2024-08-06', 181)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_list = [data['messages'][:-1] for data in test_set]\n",
    "correct_outputs = [data['messages'][-1]['content'] for data in test_set]\n",
    "\n",
    "dir_name, obj_model_outputs = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "                                                  batch=False,\n",
    "                                                  desc='data_span-seg_entity-ver2')\n",
    "dir_name, len(obj_model_outputs)\n",
    "\n",
    "# Not using batch for some tasks because of rate limit\n",
    "# dir_name, batch_job = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "#                                                   batch=True,\n",
    "#                                                   desc='data_span-seg_entity-ver2')\n",
    "# dir_name, batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_JqFQSt6gdH8BBa7BHgVYpeFH', completion_window='24h', created_at=1726578398, endpoint='/v1/chat/completions', input_file_id='file-bWlE4mEreTE1ns9Va1l1Gr69', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-2024-08-06 in organization org-B2C2pNzAq4paAOvhIYdFJlSv. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1726664798, failed_at=1726578399, finalizing_at=None, in_progress_at=None, metadata={'description': 'data_span-seg_entity-ver2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_utils.wait_for_batch_job_finish(batch_job.id)\n",
    "# llm_utils.retrieve_batch_query_result()\n",
    "# llm_utils.combine_batch_query_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
