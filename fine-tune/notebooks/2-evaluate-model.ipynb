{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import fine_tune.annotation_utils as a_utils\n",
    "import fine_tune.llm_utils as llm_utils\n",
    "import fine_tune.message_utils as m_utils\n",
    "from fine_tune.env import (\n",
    "    BRAT_DATA_PATH,\n",
    ")\n",
    "from job_preset import JOB_PRESET\n",
    "import os\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('action-seg-v2-d3',\n",
       " 'ft:gpt-4o-mini-2024-07-18:rui:action-seg-v2-d3:AAPffHbH',\n",
       " 133,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are an annotation expert. You will be given a segment of a privacy policy of a web or mobile application, and will be asked to annotate actions in it.\\n\\nIMPORTANT: Filtering Out General Phrases\\nBefore annotating, carefully check each potential data entity. DO NOT annotate sentences that do not provide specific data types or purpose types.\\nExamples of general phrases to omit include, but are not limited to:\\n\\n\"the information we collect about you\"\\n\"other data\"\\n\"any information\"\\n\"other purposes\"\\n\"purposes described in our policy\"\\n\\nIf a sentence does not clearly indicate a specific type of personal data, DO NOT include it in your annotations.\\n\\nData usage context refers to the (core phrases within) sentences that mention the actions that are being taken with the PERSONAL DATA OF THE USER which is being mentioned in one of the following context types:\\n1. first-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by the first party (the application).\\n2. third-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by a third party.\\n3. third-party-sharing-disclosure - the policy segment mentions sharing, or disclosure of this datum to a third party.\\n4. data-storage-retention-deletion - the policy segment mentions storage, retention, or deletion of this datum.\\n5. data-security-protection - the policy segment mentions how this datum is being protected.\\n\\nNote the following!\\n1. Personal user data that is mentioned outside of one of these contexts does not classify as data entity.\\n2. Multiple contexts may apply to the same data entity.\\n3. Tracking technologies such as cookies, web beacons, etc. are technologies, hence does not classify as data entity and should NOT be annotated.\\n4. The policy segment that you receive might be empty or not contain any information on usage of concrete personal user data - that\\'s normal, and you should just return an empty list.\\n\\nProvide the output as a list of data usage contexts with the following details for each entry:\\n1. The type of the context as in one of the five context types mentioned above.\\n2. The exact text of the context as it appears in the text segment.\\n3. The exact sentence of the context as it appears in the text segment.\\n\\nYou will be given the segment below from user input. Please identify and annotate ALL data usage contexts in the following privacy policy segment.\\nYour output should follow this JSON structure:\\n\\n[\\n    {\\n        \"action_type\": \"...\",\\n        \"text\": \"...\",\\n        \"sentence\": \"...\"\\n    },\\n    {\\n        \"action_type\": \"...\",\\n        \"text\": \"...\",\\n        \"sentence\": \"...\"\\n    }\\n]\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Please annotate the following segment:\\n\\nTHIRD PARTY SERVICES\\n\\nWhile using the Services you may encounter links to third party websites, services or applications. Please keep in mind that this Privacy Policy does not apply to any third party websites, services or applications, even if they are accessible, downloadable, or otherwise distributed through the Services.\\nPlease be advised that such third party websites, services or applications are independent from the Company. We assume no responsibility or liability whatsoever with regard to privacy matters or any other legal matter with respect to such third party websites and/or services. We encourage you to carefully read the privacy policies and the terms of use of such third party websites and/or services, as their terms, not ours, will apply to any of your interactions with such third parties.\\nYou should always review their privacy practices carefully before providing Personal Information to such third parties.\\nYou are knowingly and voluntarily assuming all risks of using any third-party websites, services or applications. You agree that we shall have no liability whatsoever with respect to such third party sites and your usage of them.\\n\\n\\n'},\n",
       "   {'role': 'assistant', 'content': '[]'}]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job_desc_dir = None\n",
    "job_desc_dir = 'fine_tune-2024-09-22-23-42-28-gpt-4o-mini-2024-07-18'\n",
    "\n",
    "job_desc = llm_utils.load_fine_tune_description(job_desc_dir)\n",
    "\n",
    "job_preset = JOB_PRESET[job_desc]\n",
    "\n",
    "data_entities = job_preset.load_data()\n",
    "all_data = job_preset.as_training_data(data_entities)\n",
    "training_set, validation_set, test_set, fine_tuned_model_id = llm_utils.load_eval_info(job_desc_dir, all_data=all_data)\n",
    "\n",
    "job_desc, fine_tuned_model_id, len(test_set), test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or, load from non-preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1067"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For (segment, data_span)\n",
    "# data_entities = a_utils.load_data_entities_of_segments()\n",
    "\n",
    "# data_entities = [segment for segment in data_entities if segment['entities']]\n",
    "\n",
    "# For data span\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_segment(data_entities)\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_segment_1_1(data_entities)\n",
    "# For data classification\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment(data_entities)\n",
    "# For data classification (gradual, level 0)\n",
    "# all_data = m_utils.as_training_data_for_data_classification_of_segment_gradual(data_entities)\n",
    "\n",
    "## For (segment, sentence, data_span)\n",
    "# data_entities = a_utils.load_data_entities_of_sentences()\n",
    "# For data span of sentence\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence(data_entities)  # data_entity-seg_sent_data-v2\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence_1(data_entities)\n",
    "# all_data = m_utils.as_training_data_for_data_span_of_sentence_only(data_entities)  # data_entity-sent_data-ver2\n",
    "\n",
    "\n",
    "## For (sentence, purpose_span)\n",
    "# purpose_entities = a_utils.load_purpose_entities_of_sentences()\n",
    "# For purpose span of sentence\n",
    "# all_data = m_utils.as_training_data_for_purpose_span_of_sentence_only(purpose_entities)\n",
    "\n",
    "\n",
    "## For (segment, (sentence, action_type, text))\n",
    "# action_entities = a_utils.load_actions_of_segments()\n",
    "# For action type of sentences\n",
    "# all_data = m_utils.as_training_data_for_action_span_for_segment(action_entities)\n",
    "\n",
    "## For (segment, sentence, action_type, text)\n",
    "action_entities = a_utils.load_and_get(a_utils.get_actions_of_sentences)\n",
    "# For action type of sentence\n",
    "all_data = m_utils.as_training_data_for_action_span_of_sentence_only(action_entities)\n",
    "\n",
    "\n",
    "job_desc = 'action-sent'\n",
    "\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load from a previous fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 8, 1019)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job_desc_dir = None\n",
    "job_desc_dir = 'fine_tune-2024-09-18-19-35-56-gpt-4o-mini-2024-07-18'\n",
    "\n",
    "training_set, validation_set, test_set, fine_tuned_model_id = llm_utils.load_eval_info(job_desc_dir, all_data=all_data)\n",
    "\n",
    "len(training_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or, Use the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are an annotation expert. You will be given a segment of a privacy policy of a web or mobile application, and will be asked to annotate actions in it.\\n\\nIMPORTANT: Filtering Out General Phrases\\nBefore annotating, carefully check each potential data entity. DO NOT annotate sentences that do not provide specific data types or purpose types.\\nExamples of general phrases to omit include, but are not limited to:\\n\\n\"the information we collect about you\"\\n\"other data\"\\n\"any information\"\\n\"other purposes\"\\n\"purposes described in our policy\"\\n\\nIf a sentence does not clearly indicate a specific type of personal data, DO NOT include it in your annotations.\\n\\nData usage context refers to the (core phrases within) sentences that mention the actions that are being taken with the PERSONAL DATA OF THE USER which is being mentioned in one of the following context types:\\n1. first-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by the first party (the application).\\n2. third-party-collection-use - the policy segment mentions collection, usage, or processing of this datum by a third party.\\n3. third-party-sharing-disclosure - the policy segment mentions sharing, or disclosure of this datum to a third party.\\n4. data-storage-retention-deletion - the policy segment mentions storage, retention, or deletion of this datum.\\n5. data-security-protection - the policy segment mentions how this datum is being protected.\\n\\nNote the following!\\n1. Personal user data that is mentioned outside of one of these contexts does not classify as data entity.\\n2. Multiple contexts may apply to the same data entity.\\n3. Tracking technologies such as cookies, web beacons, etc. are technologies, hence does not classify as data entity and should NOT be annotated.\\n4. The policy segment that you receive might be empty or not contain any information on usage of concrete personal user data - that\\'s normal, and you should just return an empty list.\\n\\nProvide the output as a list of data usage contexts with the following details for each entry:\\n1. The type of the context as in one of the five context types mentioned above.\\n2. The exact text of the context as it appears in the text segment.\\n3. The exact sentence of the context as it appears in the text segment.\\n\\nYou will be given the segment below from user input. Please identify and annotate ALL data usage contexts in the following privacy policy segment.\\nYour output should follow this JSON structure:\\n\\n[\\n    {\\n        \"action_type\": \"...\",\\n        \"text\": \"...\",\\n    },\\n    {\\n        \"action_type\": \"...\",\\n        \"text\": \"...\",\\n    }\\n]\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Please annotate the following segment:\\n\\n101 Great Goals Privacy Policy\\n'},\n",
       "   {'role': 'assistant', 'content': '[]'}]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_set = all_data\n",
    "\n",
    "len(test_set), test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft:gpt-4o-mini-2024-07-18:rui:action-seg-v2-d3:AAPffHbH',\n",
       " 'action-seg-v2-d3',\n",
       " 133)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_id = fine_tuned_model_id if 'fine_tuned_model_id' in locals() else 'gpt-4o-mini-2024-07-18'\n",
    "# model_id = '4.0Ultra'\n",
    "# model_id = 'gpt-4o-2024-08-06'\n",
    "# model_id = 'ft:gpt-4o-2024-08-06:rui:test:A8rFT3EN'\n",
    "\n",
    "desc = job_desc if 'job_desc' in locals() else None\n",
    "\n",
    "# test_set = test_set[284:]\n",
    "\n",
    "model_id, desc, len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:12<00:00,  1.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('eval-2024-09-23-21-51-37-ft:gpt-4o-mini-2024-07-18:rui:action-seg-v2-d3:AAPffHbH',\n",
       " 133)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_list = [data['messages'][:-1] for data in test_set]\n",
    "correct_outputs = [data['messages'][-1]['content'] for data in test_set]\n",
    "\n",
    "dir_name, obj_model_outputs = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "                                                  batch=False,\n",
    "                                                  desc=desc)\n",
    "dir_name, len(obj_model_outputs)\n",
    "\n",
    "# Not using batch for some tasks because of rate limit\n",
    "# dir_name, batch_job = llm_utils.query_llm(model_id, messages_list, correct_outputs=correct_outputs,\n",
    "#                                                   batch=True,\n",
    "#                                                   desc=desc)\n",
    "# dir_name, batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_JqFQSt6gdH8BBa7BHgVYpeFH', completion_window='24h', created_at=1726578398, endpoint='/v1/chat/completions', input_file_id='file-bWlE4mEreTE1ns9Va1l1Gr69', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-2024-08-06 in organization org-B2C2pNzAq4paAOvhIYdFJlSv. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1726664798, failed_at=1726578399, finalizing_at=None, in_progress_at=None, metadata={'description': 'data_span-seg_entity-ver2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_utils.wait_for_batch_job_finish(batch_job.id)\n",
    "# llm_utils.retrieve_batch_query_result()\n",
    "# llm_utils.combine_batch_query_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
